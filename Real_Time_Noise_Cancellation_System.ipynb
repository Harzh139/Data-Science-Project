{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcOR3_F1f-LZ"
      },
      "outputs": [],
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter, stft, istft\n",
        "from scipy.ndimage import median_filter\n",
        "\n",
        "# Function for high-pass filter\n",
        "def butter_highpass(cutoff, fs, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def highpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_highpass(cutoff, fs, order=order)\n",
        "    return lfilter(b, a, data)\n",
        "\n",
        "# Function for spectral subtraction with Wiener filter\n",
        "def noise_reduction_spectral(audio_chunk, noise_estimation, alpha=1.5):\n",
        "    f, t, Zxx = stft(audio_chunk, fs=44100, nperseg=512)\n",
        "    noise_power = np.abs(noise_estimation)**2\n",
        "    magnitude = np.abs(Zxx)\n",
        "    phase = np.angle(Zxx)\n",
        "\n",
        "    # Apply spectral subtraction with a smoothing factor\n",
        "    reduced_magnitude = np.maximum(magnitude - alpha * noise_power, 0)\n",
        "\n",
        "    # Wiener filtering (in the frequency domain)\n",
        "    noise_magnitude = np.sqrt(noise_power)\n",
        "    signal_magnitude = np.sqrt(magnitude**2 - noise_power)\n",
        "    wiener_filter = np.clip(signal_magnitude / (signal_magnitude + noise_magnitude), 0, 1)\n",
        "\n",
        "    # Apply Wiener filter to the magnitude\n",
        "    enhanced_magnitude = reduced_magnitude * wiener_filter\n",
        "\n",
        "    # Reconstruct the signal using enhanced magnitude and the original phase\n",
        "    Zxx_reduced = enhanced_magnitude * np.exp(1j * phase)\n",
        "    _, audio_reconstructed = istft(Zxx_reduced, fs=44100)\n",
        "\n",
        "    # Normalize the output to avoid clipping\n",
        "    audio_reconstructed = np.int16(np.clip(audio_reconstructed / np.max(np.abs(audio_reconstructed)), -1, 1) * 32767)\n",
        "\n",
        "    # Apply median filter to smooth out high-frequency noise\n",
        "    audio_reconstructed = median_filter(audio_reconstructed, size=3)\n",
        "\n",
        "    return audio_reconstructed\n",
        "\n",
        "# Parameters\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 1\n",
        "RATE = 44100\n",
        "CHUNK = 8820  # ~200 ms chunks\n",
        "RECORD_SECONDS = 10\n",
        "OUTPUT_FILE_SINGLE = \"single_speaker_output.wav\"\n",
        "OUTPUT_FILE_MULTI = \"multi_speaker_output.wav\"\n",
        "\n",
        "# Initialize PyAudio\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "# Open input stream\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNK)\n",
        "\n",
        "print(\"Recording and processing in real-time...\")\n",
        "\n",
        "# Noise estimation (collecting a few chunks for baseline noise profile)\n",
        "print(\"Collecting noise profile...\")\n",
        "noise_profile_chunks = []\n",
        "for _ in range(5):\n",
        "    noise_data = stream.read(CHUNK)\n",
        "    noise_audio = np.frombuffer(noise_data, dtype=np.int16)\n",
        "    noise_profile_chunks.append(noise_audio)\n",
        "noise_profile = np.mean(noise_profile_chunks, axis=0)\n",
        "\n",
        "frames_single = []\n",
        "frames_multi = []\n",
        "\n",
        "# Recording and processing audio\n",
        "for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "    data = stream.read(CHUNK)\n",
        "    audio_data = np.frombuffer(data, dtype=np.int16)\n",
        "\n",
        "    # Single speaker scenario\n",
        "    filtered_audio = highpass_filter(audio_data, cutoff=150, fs=RATE)  # Lowered cutoff for voice preservation\n",
        "    single_speaker_output = noise_reduction_spectral(filtered_audio, noise_profile)\n",
        "    frames_single.append(single_speaker_output.astype(np.int16).tobytes())\n",
        "\n",
        "    # Multi-speaker scenario\n",
        "    multi_speaker_output = noise_reduction_spectral(audio_data, noise_profile)\n",
        "    frames_multi.append(multi_speaker_output.astype(np.int16).tobytes())\n",
        "\n",
        "print(\"Recording completed.\")\n",
        "\n",
        "# Stop and close stream\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n",
        "\n",
        "# Save single speaker output\n",
        "wf_single = wave.open(OUTPUT_FILE_SINGLE, 'wb')\n",
        "wf_single.setnchannels(CHANNELS)\n",
        "wf_single.setsampwidth(p.get_sample_size(FORMAT))\n",
        "wf_single.setframerate(RATE)\n",
        "wf_single.writeframes(b''.join(frames_single))\n",
        "wf_single.close()\n",
        "\n",
        "# Save multi-speaker output\n",
        "wf_multi = wave.open(OUTPUT_FILE_MULTI, 'wb')\n",
        "wf_multi.setnchannels(CHANNELS)\n",
        "wf_multi.setsampwidth(p.get_sample_size(FORMAT))\n",
        "wf_multi.setframerate(RATE)\n",
        "wf_multi.writeframes(b''.join(frames_multi))\n",
        "wf_multi.close()\n",
        "\n",
        "print(f\"Processed audio saved as {OUTPUT_FILE_SINGLE} and {OUTPUT_FILE_MULTI}.\")"
      ]
    }
  ]
}